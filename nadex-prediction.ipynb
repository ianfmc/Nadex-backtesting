{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f07e057-7ee1-4187-adbc-01870d6e2a8b",
   "metadata": {},
   "source": [
    "**Load** the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8135450a-c614-4608-9a4f-a980e289b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade numexpr --quiet\n",
    "\n",
    "!pip install pandas --quiet\n",
    "!pip install datetime --quiet\n",
    "!pip install feedparser --quiet\n",
    "!pip install textblob --quiet\n",
    "!pip install yfinance --quiet\n",
    "!pip install requests --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f7f13-c92b-4647-9c0a-b58432c3ea92",
   "metadata": {},
   "source": [
    "**Define a function to fetch sentinment analysis for the Nadex Stocks**\n",
    "1. Start with loading the Yahoo Finance Feed\n",
    "2. Determine the Sentiment\n",
    "3. Collapse per day and average the Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2275aaa-8bc5-46e5-aac3-e4b47bbb232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feedparser\n",
    "from textblob import TextBlob\n",
    "from datetime import timedelta\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "def fetch_sentiment_records() -> List:\n",
    "    \"\"\"\n",
    "    Fetch all RSS entries and compute a sentiment score per item.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for ticker, url in TICKERS_AND_FEEDS.items():\n",
    "        feed = feedparser.parse(url)\n",
    "        for entry in feed.entries:\n",
    "            pub_ts = pd.to_datetime(entry.get(\"published\", \"\"), utc=True)\n",
    "            score = TextBlob(f\"{entry.title}. {entry.get('summary','')}\").sentiment.polarity\n",
    "            records.append({\n",
    "                \"ticker\": ticker,\n",
    "                \"Date\": pub_ts.date(),\n",
    "                \"score\": score\n",
    "            })\n",
    "    return records\n",
    "\n",
    "def get_recent_sentiment(days=180) -> pd.DataFrame:\n",
    "    \"\"\"Return mean daily sentiment per ticker over the last `days` days.\"\"\"\n",
    "    df = (\n",
    "        pd.DataFrame(fetch_sentiment_records())\n",
    "          .groupby([\"ticker\", \"Date\"], as_index=False)\n",
    "          .score.mean()\n",
    "    )\n",
    "    cutoff = (pd.Timestamp.today().normalize() - timedelta(days=days)).date()\n",
    "    return df[df.Date.ge(cutoff)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81118871-b728-48e5-831d-f8416ff02d45",
   "metadata": {},
   "source": [
    "**Define a function to get the pricing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e0da0a-4253-43ca-9c8e-62a1a0c5876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from typing import List, Tuple\n",
    "\n",
    "def fetch_price(ticker) -> pd.DataFrame:\n",
    "    df = yf.download(ticker, period=\"6mo\", interval=\"1d\", auto_adjust=True, progress=False)\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "    df.reset_index(inplace=True) \n",
    "    df.columns.name = None\n",
    "    df['ticker'] = ticker\n",
    "    return df\n",
    "\n",
    "def merge_sentiment_scores(ticker_price_data, sentiment_df):\n",
    "    \"\"\"\n",
    "    ticker_price_data: list of (ticker, price_df)\n",
    "    sentiment_df: DataFrame with ['ticker','Date','score']\n",
    "    \n",
    "    Returns: dict where key=ticker, value=merged DataFrame for that ticker\n",
    "    \"\"\"\n",
    "    # 1) Normalize sentiment Date dtype once\n",
    "    sentiment = sentiment_df.copy()\n",
    "    sentiment['Date'] = pd.to_datetime(sentiment['Date'])\n",
    "    \n",
    "    result = {}\n",
    "    for ticker, price_df in ticker_price_data:\n",
    "        # 2) Ensure price_df.Date is a datetime64 column\n",
    "        df = price_df.reset_index() if price_df.index.name == 'Date' else price_df.copy()\n",
    "        if df['Date'].dtype == object:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "        # 3) Filter sentiment to this ticker\n",
    "        daily = sentiment[sentiment['ticker'] == ticker][['Date', 'score']]\n",
    "        \n",
    "        # 4) Merge and store\n",
    "        merged_df = df.merge(daily, on='Date', how='left')\n",
    "        merged_df['ticker'] = ticker\n",
    "        \n",
    "        result[ticker] = merged_df\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a462df1-7648-4934-8487-fa19c5de5495",
   "metadata": {},
   "source": [
    "**Compute the Technical Indicators**\n",
    "\n",
    "1. Compute the MACD\n",
    "2. Compute the RSI\n",
    "3. Compute the ATR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df5833a-1a6f-4854-9c5d-cab34bcee3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_macd(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with EMA12, EMA26, MACD, Signal, and MACD_hist added.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD']  = df['EMA12'] - df['EMA26']\n",
    "    df['Signal']   = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_hist'] = df['MACD'] - df['Signal']\n",
    "    return df\n",
    "\n",
    "def compute_rsi(df: pd.DataFrame, window: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with a 14-period RSI column added.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.ewm(alpha=1/window, adjust=False).mean()\n",
    "    avg_loss = loss.ewm(alpha=1/window, adjust=False).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    return df\n",
    "\n",
    "def compute_atr(df: pd.DataFrame, window: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with a 14-period ATR column added.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    prev_close = df['Close'].shift(1)\n",
    "    tr1 = df['High'] - df['Low']\n",
    "    tr2 = (df['High'] - prev_close).abs()\n",
    "    tr3 = (df['Low']  - prev_close).abs()\n",
    "    df['ATR'] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1).rolling(window=window).mean()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932b7427-6257-407d-b996-cce27aaab9fc",
   "metadata": {},
   "source": [
    "**Load the strike prices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5018b7b6-74b5-4f15-8f2c-b4d9206518d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_strikes(\n",
    "    path: str,\n",
    "    strike_col: str = \"strike\",\n",
    "    decimals: int = 4\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1. Reads a CSV from `path`\n",
    "    2. Normalizes column names to lowercase & stripped\n",
    "    3. Ensures there's a numeric `strike_col`, stripping whitespace, converting to float, and rounding\n",
    "    \n",
    "    Returns the cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        pd.read_csv(path)\n",
    "          # normalize headers: strip whitespace, lowercase\n",
    "          .rename(columns=lambda c: c.strip().lower())\n",
    "          # strip & convert the strike column to numeric, then round\n",
    "          .assign(**{\n",
    "              strike_col: lambda df: (\n",
    "                  pd.to_numeric(\n",
    "                      df[strike_col]\n",
    "                        .astype(str)\n",
    "                        .str.strip(),\n",
    "                      errors=\"raise\"\n",
    "                  )\n",
    "                  .round(decimals)\n",
    "              )\n",
    "          })\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e818b8-8fa1-4cec-8a69-1ec208a838fc",
   "metadata": {},
   "source": [
    "**Determine the Trading Signal**\n",
    "\n",
    "1. Determine the Trend\n",
    "2. Check the Momentum\n",
    "3. Determine the Trigger\n",
    "4. Check the Volatility\n",
    "5. Check the Sentiment\n",
    "6. Generate the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889eb1cd-4e7d-430d-bbdb-2a4d2c8edd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def determine_trend(row):\n",
    "    \"\"\"\n",
    "    Returns (trend_str, ema_diff) where ema_diff = EMA12 − EMA26.\n",
    "    \"\"\"\n",
    "    diff = row.EMA12 - row.EMA26\n",
    "    if (row.EMA12 > row.EMA26) and (row.Close > row.EMA12) and (row.Close > row.EMA26):\n",
    "        trend = 'up'\n",
    "    elif (row.EMA12 < row.EMA26) and (row.Close < row.EMA12) and (row.Close < row.EMA26):\n",
    "        trend = 'down'\n",
    "    else:\n",
    "        trend = 'sideways'\n",
    "    return trend, diff\n",
    "\n",
    "def momentum_check(row, trend):\n",
    "    \"\"\"\n",
    "    Returns (ok, rsi) where ok is True/False and rsi is the raw RSI value.\n",
    "    \"\"\"\n",
    "    rsi = row.RSI\n",
    "    if trend == 'up':\n",
    "        ok = (rsi > 50) and ((row.MACD > row.Signal) or (row.MACD_hist > 0))\n",
    "    elif trend == 'down':\n",
    "        ok = (rsi < 50) and ((row.MACD < row.Signal) or (row.MACD_hist < 0))\n",
    "    else:\n",
    "        ok = False\n",
    "    return ok, rsi\n",
    "\n",
    "def signal_trigger(row, trend):\n",
    "    \"\"\"\n",
    "    Returns (ok, macd_diff) where macd_diff = MACD − Signal.\n",
    "    \"\"\"\n",
    "    macd_diff = row.MACD - row.Signal\n",
    "    if trend == 'up':\n",
    "        ok = (macd_diff > 0) and (row.RSI > 50)\n",
    "    elif trend == 'down':\n",
    "        ok = (macd_diff < 0) and (row.RSI < 50)\n",
    "    else:\n",
    "        ok = False\n",
    "    return ok, macd_diff\n",
    "\n",
    "def volatility_check(row, strike_diff):\n",
    "    \"\"\"\n",
    "    Returns (ok, strike_diff) so you have the raw distance too.\n",
    "    \"\"\"\n",
    "    ok = strike_diff <= 0.5 * row.ATR\n",
    "    return ok, strike_diff\n",
    "\n",
    "def sentiment_check(row, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Returns (ok, score) so you keep the raw sentiment polarity.\n",
    "    \"\"\"\n",
    "    score = row.score\n",
    "    ok = score > -threshold\n",
    "    return ok, score\n",
    "\n",
    "def signal_detail_for_row(row, per_ticker, expiry=\"EOD\"):\n",
    "    df = per_ticker[row.ticker]\n",
    "    last = df.iloc[-1]\n",
    "\n",
    "    trend, trend_val = determine_trend(last)\n",
    "    momentum_ok, momentum_val = momentum_check(last, trend)\n",
    "    sig_ok, signal_val = signal_trigger(last, trend)\n",
    "    strike_diff = abs(row.strike - last.Close)\n",
    "    vol_ok, vol_val = volatility_check(last, strike_diff)\n",
    "    sent_ok, sent_val = sentiment_check(last)\n",
    "\n",
    "    # build recommendation + contract price\n",
    "    if (trend == 'sideways'\n",
    "        or not momentum_ok\n",
    "        or not sig_ok\n",
    "        or not vol_ok\n",
    "        or not sent_ok\n",
    "    ):\n",
    "        rec   = \"No trade\"\n",
    "        price = pd.NA\n",
    "    else:\n",
    "        direction = \"Buy\" if trend == \"up\" else \"Sell\"\n",
    "        price     = 10 * (0.5 - (strike_diff / (2 * last.ATR)))\n",
    "        rec       = direction\n",
    "\n",
    "    return pd.Series({\n",
    "        \"Date\":           pd.Timestamp.now().strftime(\"%d-%b-%y\"),\n",
    "        \"Ticker\":         row.ticker,\n",
    "        \"Strike\":         row.strike,\n",
    "        \"EMA12\":          last.EMA12,\n",
    "        \"EMA26\":          last.EMA26,\n",
    "        \"MACD\":           last.MACD,\n",
    "        \"RSI\":            last.RSI,\n",
    "        \"ATR\":            last.ATR,\n",
    "        \"Recommendation\": rec,\n",
    "        \"ContractPrice\":  price,\n",
    "        \"Trend\":          trend_val,\n",
    "        \"Momentum\":       momentum_val,\n",
    "        \"Signal\":         signal_val,\n",
    "        \"Volatility\":     vol_val,\n",
    "        \"Sentiment\":      sent_val,\n",
    "    })\n",
    "\n",
    "def generate_detailed_signals(per_ticker: dict[str,pd.DataFrame],\n",
    "                              strikes_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies signal_detail_for_row to every strike, returning a DataFrame\n",
    "    with separate columns for both the boolean/string and the raw measure.\n",
    "    \"\"\"\n",
    "    return strikes_df.apply(\n",
    "        lambda r: signal_detail_for_row(r, per_ticker),\n",
    "        axis=1\n",
    "    )    \n",
    "\n",
    "def generate_trade_signal(df: pd.DataFrame, asset_symbol: str, strike_price: float, expiry=\"EOD\") -> str:\n",
    "    \"\"\"\n",
    "    Look only at the *last* row of df and decide on a trade recommendation.\n",
    "    \"\"\"\n",
    "    last = df.iloc[-1]\n",
    "    trend = determine_trend(last)\n",
    "    if trend == 'sideways':\n",
    "        return \"No trade: Trend unclear.\"\n",
    "    if trend == 'down':\n",
    "        # optional debug print\n",
    "        print(f\"Down trend for {asset_symbol} at {strike_price:.4f}\")\n",
    "\n",
    "    if not momentum_check(last, trend):\n",
    "        return \"No trade: Momentum not aligned.\"\n",
    "    if not signal_trigger(last, trend):\n",
    "        return \"No trade: No signal trigger.\"\n",
    "\n",
    "    strike_diff = abs(strike_price - last.Close)\n",
    "    if not volatility_check(last, strike_diff):\n",
    "        return \"No trade: Strike too far based on ATR.\"\n",
    "    if not sentiment_check(last):\n",
    "        return \"No trade: Negative sentiment contradicts signal.\"\n",
    "\n",
    "    # crude price proxy\n",
    "    price_est = 10 * (0.5 - (strike_diff / (2 * last.ATR)))\n",
    "    direction = \"Buy\" if trend == 'up' else \"Sell\"\n",
    "    return (\n",
    "        f\"{direction} {asset_symbol} @ {strike_price:.4f} (EOD) ≈ ${price_est:.1f}. \"\n",
    "        f\"{trend.title()} trend, momentum/signal OK, volatility OK, sentiment OK.\"\n",
    "    )\n",
    "\n",
    "def generate_all_signals(\n",
    "    per_ticker: dict[str, pd.DataFrame], \n",
    "    strikes_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each row in strikes_df, look up its ticker-DF in per_ticker and\n",
    "    call generate_trade_signal.  Returns a DataFrame of recommendations.\n",
    "    \"\"\"\n",
    "    out = (\n",
    "        strikes_df\n",
    "        .assign(\n",
    "            Date=pd.Timestamp.now().strftime('%d-%b-%y'),\n",
    "            Signal=lambda d: d.apply(\n",
    "                lambda r: generate_trade_signal(\n",
    "                    per_ticker[r.ticker],\n",
    "                    r.ticker,\n",
    "                    r.strike\n",
    "                ),\n",
    "                axis=1\n",
    "            )\n",
    "        )\n",
    "        .rename(columns={'ticker':'Ticker', 'strike':'Strike'})\n",
    "        [['Date','Ticker','Strike','Signal']]\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0786f5-e146-4cf1-9c88-0978f4e6d6e9",
   "metadata": {},
   "source": [
    "**Define a function to upload the recommendations to S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e597f1d-9032-4da6-a35d-ce15f3dde6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from botocore.exceptions import ClientError\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "from typing import Iterable, List, Dict\n",
    "\n",
    "def create_s3_clients(\n",
    "    profile: str = \"default\", region: str = \"us-east-1\"\n",
    ") -> Dict[str, boto3.client]:\n",
    "    session = boto3.Session(profile_name=profile, region_name=region)\n",
    "    return {\n",
    "        \"public\": session.client(\n",
    "            \"s3\",\n",
    "            config=Config(signature_version=UNSIGNED),\n",
    "            region_name=region,\n",
    "        ),\n",
    "        \"private\": session.client(\"s3\"),\n",
    "        \"resource\": session.resource(\"s3\"),\n",
    "    }\n",
    "\n",
    "def get_bucket(resource: boto3.resource, name: str):\n",
    "    return resource.Bucket(name)\n",
    "\n",
    "def upload_df_to_s3(\n",
    "    df: pd.DataFrame,\n",
    "    bucket: str,\n",
    "    key: str,\n",
    "    region: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Uploads a DataFrame to S3 as CSV. Verifies bucket existence first.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    bucket : str\n",
    "        Name of the S3 bucket (no leading/trailing spaces).\n",
    "    key : str\n",
    "        S3 object key, e.g. \"csv/2025-06-28-results.csv\"\n",
    "    region : str, optional\n",
    "        AWS region where the bucket resides.\n",
    "    \"\"\"\n",
    "    bucket = bucket.strip()\n",
    "    s3 = boto3.client('s3', region_name=region)\n",
    "\n",
    "    try:\n",
    "        s3.head_bucket(Bucket=bucket)\n",
    "    except ClientError as e:\n",
    "        code = e.response['Error']['Code']\n",
    "        msg = e.response['Error']['Message']\n",
    "        raise RuntimeError(\n",
    "            f\"Could not access bucket '{bucket}' (region={region}): {msg} (code {code})\"\n",
    "        ) from e\n",
    "\n",
    "    buffer = io.StringIO()\n",
    "    df.to_csv(buffer, index=False)\n",
    "    buffer.seek(0)\n",
    "\n",
    "    try:\n",
    "        s3.put_object(Bucket=bucket, Key=key, Body=buffer.getvalue())\n",
    "        print(f\"✅ Uploaded to s3://{bucket}/{key}\")\n",
    "    except ClientError as e:\n",
    "        raise RuntimeError(\n",
    "            f\"Failed to upload CSV to s3://{bucket}/{key}: \"\n",
    "            f\"{e.response['Error']['Message']}\"\n",
    "        ) from e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d1b12-c689-414c-a739-0a7dea03c8b6",
   "metadata": {},
   "source": [
    "**Define a function to run the Pipeline**\n",
    "1. Get the news and create the Sentiment Analysis\n",
    "2. Collect pricing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c098fd63-8ecb-45f6-8908-78d9ef151c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def run_prediction_pipeline(tickers_and_feeds: List,\n",
    "                           bucket_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch price & sentiment, compute indicators, load strikes,\n",
    "    and return a DataFrame of trade signals.\n",
    "    \"\"\"\n",
    "    clients = create_s3_clients()\n",
    "    public_s3 = clients[\"public\"]\n",
    "    private_s3 = clients[\"private\"]\n",
    "    s3_resource = clients[\"resource\"]\n",
    "    buckets = {\n",
    "        \"daily\":  get_bucket(s3_resource, bucket_name),\n",
    "    }\n",
    "\n",
    "    ticker_price_data = [\n",
    "        (ticker, fetch_price(ticker))\n",
    "        for ticker in tickers_and_feeds\n",
    "    ]\n",
    "\n",
    "    merged = merge_sentiment_scores(ticker_price_data,\n",
    "                                    get_recent_sentiment(DAYS_TO_INCLUDE))\n",
    "    processed = {\n",
    "        ticker: (\n",
    "            df\n",
    "              .pipe(compute_macd)\n",
    "              .pipe(compute_rsi)\n",
    "              .pipe(compute_atr)\n",
    "        )\n",
    "        for ticker, df in merged.items()\n",
    "    }\n",
    "    strikes_df = load_strikes(\"contracts.csv\")\n",
    "    signals_df = generate_detailed_signals(processed, strikes_df)\n",
    "\n",
    "    today_str = date.today().strftime('%Y%m%d')\n",
    "\n",
    "    s3_key = f\"recommendations/{today_str}.csv\"\n",
    "    upload_df_to_s3(\n",
    "        signals_df,    \n",
    "        bucket_name,   \n",
    "        s3_key         \n",
    "    )\n",
    "    \n",
    "    return signals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d39070-1575-404b-b913-5db05955047b",
   "metadata": {},
   "source": [
    "**Define a function to show interesting trades**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "691e8131-e1e0-4856-a7d1-4c271cd7ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_interesting_trades(df: pd.DataFrame) -> None:\n",
    "    interesting_trades_df = df[\n",
    "        ~df['Recommendation']\n",
    "            .str.contains(\"No trade\", case=False, na=False)\n",
    "    ]\n",
    "    if not interesting_trades_df.empty:\n",
    "        print(\n",
    "            tabulate(\n",
    "                interesting_trades_df[[\"Date\",\"Ticker\",\"Recommendation\",\"Strike\",\"ContractPrice\"]],\n",
    "                headers='keys',\n",
    "                tablefmt='fancy_grid',\n",
    "                showindex=False,        \n",
    "                maxcolwidths=200  \n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\"No trades recommended today\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95340ba3-8b7b-427d-8899-b1a491df5111",
   "metadata": {},
   "source": [
    "**Run the pipeine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16ddf9d5-6153-4f89-b4bd-ff5ab4782590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded to s3://nadex-daily-results/recommendations/20250701.csv\n",
      "╒═══════════╤══════════╤══════════════════╤══════════╤═════════════════╕\n",
      "│ Date      │ Ticker   │ Recommendation   │   Strike │   ContractPrice │\n",
      "╞═══════════╪══════════╪══════════════════╪══════════╪═════════════════╡\n",
      "│ 01-Jul-25 │ ES=F     │ Buy              │   6280.8 │         3.18106 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ ES=F     │ Buy              │   6268.8 │         4.00318 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ ES=F     │ Buy              │   6256.8 │         4.8253  │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ ES=F     │ Buy              │   6244.8 │         4.35258 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ ES=F     │ Buy              │   6232.8 │         3.53046 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ ES=F     │ Buy              │   6220.8 │         2.70834 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ NQ=F     │ Buy              │  23029   │         2.90043 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ NQ=F     │ Buy              │  22981   │         3.65392 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ NQ=F     │ Buy              │  22933   │         4.40741 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ NQ=F     │ Buy              │  22885   │         4.8391  │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ NQ=F     │ Buy              │  22837   │         4.08561 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ NQ=F     │ Buy              │  22789   │         3.33212 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ NQ=F     │ Buy              │  22741   │         2.57863 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ YM=F     │ Buy              │  44650   │         2.85887 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ YM=F     │ Buy              │  44550   │         3.79796 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ YM=F     │ Buy              │  44450   │         4.73705 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ YM=F     │ Buy              │  44350   │         4.32385 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 01-Jul-25 │ YM=F     │ Buy              │  44250   │         3.38476 │\n",
      "╘═══════════╧══════════╧══════════════════╧══════════╧═════════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "DAYS_TO_INCLUDE = 90 \n",
    "TICKERS_AND_FEEDS = {\n",
    "    'CL=F': 'https://finance.yahoo.com/rss/headline?s=CL=F',\n",
    "    'ES=F': 'https://finance.yahoo.com/rss/headline?s=ES=F',\n",
    "    'GC=F': 'https://finance.yahoo.com/rss/headline?s=GC=F',\n",
    "    'NQ=F': 'https://finance.yahoo.com/rss/headline?s=NQ=F',\n",
    "    'RTY=F': 'https://finance.yahoo.com/rss/headline?s=RTY=F',\n",
    "    'YM=F': 'https://finance.yahoo.com/rss/headline?s=YM=F',\n",
    "    'AUDUSD=X': 'https://finance.yahoo.com/rss/headline?s=AUDUSD=X',\n",
    "    'EURJPY=X': 'https://finance.yahoo.com/rss/headline?s=EURJPY=X',\n",
    "    'EURUSD=X': 'https://finance.yahoo.com/rss/headline?s=EURUSD=X',\n",
    "    'GBPJPY=X': 'https://finance.yahoo.com/rss/headline?s=GBPJPY=X',\n",
    "    'GBPUSD=X': 'https://finance.yahoo.com/rss/headline?s=GBPUSD=X',\n",
    "    'USDCAD=X': 'https://finance.yahoo.com/rss/headline?s=USDCAD=X',\n",
    "    'USDCHF=X': 'https://finance.yahoo.com/rss/headline?s=USDCHF=X',\n",
    "    'USDJPY=X': 'https://finance.yahoo.com/rss/headline?s=USDJPY=X'\n",
    "}\n",
    "\n",
    "show_interesting_trades(\n",
    "    run_prediction_pipeline(TICKERS_AND_FEEDS, \n",
    "                            \"nadex-daily-results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad1b8e-332a-4905-9061-5a74ee8dc1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
